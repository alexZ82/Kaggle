{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "import matplotlib\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix, vstack, lil_matrix\n",
    "from os.path import isfile\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy import sparse, io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                           processed  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestions on impr...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_comment_text(txt):\n",
    "    ntxt = re.sub(r\"[^a-zA-Z]\", \" \", txt)\n",
    "    ntxt = ntxt.lower()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = nltk.word_tokenize(ntxt)\n",
    "    return ' '.join([lemmatizer.lemmatize(w,'v') for w in text])\n",
    "\n",
    "train_data['processed'] = train_data.comment_text.apply(process_comment_text)\n",
    "test_data['processed'] = test_data.comment_text.apply(process_comment_text)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Make features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# see how frequent frequent words are\n",
    "stop = set(stopwords.words('english'))\n",
    "text = nltk.word_tokenize(' '.join(train_data.processed.values))\n",
    "dist = nltk.FreqDist(text)\n",
    "freq=[(w, dist[w]) for w in sorted(dist, key=dist.get, reverse=True) if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('article', 74553), ('page', 57296), ('wikipedia', 48625), ('edit', 40862), ('talk', 40500), ('use', 33257), ('make', 30575), ('please', 29976), ('would', 29323), ('one', 29199), ('like', 28739), ('think', 25743), ('see', 25574), ('say', 25520), ('know', 24313), ('source', 23941), ('thank', 23896), ('get', 22857), ('go', 21878), ('also', 20643)]\n",
      "[('wheatear', 1), ('dracul', 1), ('bestbuy', 1), ('itried', 1), ('defaultsorting', 1), ('mischievious', 1), ('photocatbot', 1), ('mufaddalqn', 1), ('samanthapuckettindo', 1), ('markdrows', 1), ('murtazajamali', 1), ('distributorscientiae', 1), ('hispavista', 1), ('amblocked', 1), ('bmattson', 1), ('webaddress', 1), ('gratest', 1), ('hanumakonda', 1), ('automakers', 1), ('ciu', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(freq[:20])\n",
    "print(freq[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getwordlist(data,minfreq,maxfreq):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    text = nltk.word_tokenize(' '.join(data))\n",
    "    dist = nltk.FreqDist(text)\n",
    "    wordlist = [i for i in dist.keys() if dist[i]>minfreq and dist[i]<maxfreq and i not in stop]\n",
    "    return wordlist\n",
    "\n",
    "words = getwordlist(data=train_data.processed.values,minfreq=5,maxfreq=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_features(data,name):\n",
    "    X = csr_matrix((0, len(words)))\n",
    "\n",
    "    # for every comment check if the words corresponding to our input vector exist\n",
    "    count=0\n",
    "    print(name)\n",
    "    for i in data.processed: #.loc[:100]:\n",
    "        if count%1000==0:\n",
    "            print(round(((count+1)/len(data.processed))*100,3),'%')\n",
    "        cw = set(nltk.word_tokenize(i))\n",
    "        add = [int(w in cw) for w in words]\n",
    "        X = vstack([X, csr_matrix(add)], 'csr')\n",
    "        count+=1\n",
    "    io.mmwrite(name+'_X.mtx', X)\n",
    "    \n",
    "    if len(data.columns)>3:\n",
    "        y = data.apply(lambda x: x[2:8],axis=1) # .loc[:100]\n",
    "        y = csr_matrix(y.values)\n",
    "        io.mmwrite(name+'_y.mtx', y)\n",
    "    \n",
    "    # X is shape (number of examples in the data) x (numer of feature words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data\n",
      "0.001 %\n",
      "0.627 %\n",
      "1.254 %\n",
      "1.881 %\n",
      "2.507 %\n",
      "3.134 %\n",
      "3.761 %\n",
      "4.387 %\n",
      "5.014 %\n",
      "5.641 %\n",
      "6.267 %\n",
      "6.894 %\n",
      "7.521 %\n",
      "8.147 %\n",
      "8.774 %\n",
      "9.401 %\n",
      "10.028 %\n",
      "10.654 %\n",
      "11.281 %\n",
      "11.908 %\n",
      "12.534 %\n",
      "13.161 %\n",
      "13.788 %\n",
      "14.414 %\n",
      "15.041 %\n",
      "15.668 %\n",
      "16.294 %\n",
      "16.921 %\n",
      "17.548 %\n",
      "18.174 %\n",
      "18.801 %\n",
      "19.428 %\n",
      "20.054 %\n",
      "20.681 %\n",
      "21.308 %\n",
      "21.934 %\n",
      "22.561 %\n",
      "23.188 %\n",
      "23.814 %\n",
      "24.441 %\n",
      "25.068 %\n",
      "25.695 %\n",
      "26.321 %\n",
      "26.948 %\n",
      "27.575 %\n",
      "28.201 %\n",
      "28.828 %\n",
      "29.455 %\n",
      "30.081 %\n",
      "30.708 %\n",
      "31.335 %\n",
      "31.961 %\n",
      "32.588 %\n",
      "33.215 %\n",
      "33.841 %\n",
      "34.468 %\n",
      "35.095 %\n",
      "35.721 %\n",
      "36.348 %\n",
      "36.975 %\n",
      "37.601 %\n",
      "38.228 %\n",
      "38.855 %\n",
      "39.481 %\n",
      "40.108 %\n",
      "40.735 %\n",
      "41.362 %\n",
      "41.988 %\n",
      "42.615 %\n",
      "43.242 %\n",
      "43.868 %\n",
      "44.495 %\n",
      "45.122 %\n",
      "45.748 %\n",
      "46.375 %\n",
      "47.002 %\n",
      "47.628 %\n",
      "48.255 %\n",
      "48.882 %\n",
      "49.508 %\n",
      "50.135 %\n",
      "50.762 %\n",
      "51.388 %\n",
      "52.015 %\n",
      "52.642 %\n",
      "53.268 %\n",
      "53.895 %\n",
      "54.522 %\n",
      "55.148 %\n",
      "55.775 %\n",
      "56.402 %\n",
      "57.029 %\n",
      "57.655 %\n",
      "58.282 %\n",
      "58.909 %\n",
      "59.535 %\n",
      "60.162 %\n",
      "60.789 %\n",
      "61.415 %\n",
      "62.042 %\n",
      "62.669 %\n",
      "63.295 %\n",
      "63.922 %\n",
      "64.549 %\n",
      "65.175 %\n",
      "65.802 %\n",
      "66.429 %\n",
      "67.055 %\n",
      "67.682 %\n",
      "68.309 %\n",
      "68.935 %\n",
      "69.562 %\n",
      "70.189 %\n",
      "70.815 %\n",
      "71.442 %\n",
      "72.069 %\n",
      "72.696 %\n",
      "73.322 %\n",
      "73.949 %\n",
      "74.576 %\n",
      "75.202 %\n",
      "75.829 %\n",
      "76.456 %\n",
      "77.082 %\n",
      "77.709 %\n",
      "78.336 %\n",
      "78.962 %\n",
      "79.589 %\n",
      "80.216 %\n",
      "80.842 %\n",
      "81.469 %\n",
      "82.096 %\n",
      "82.722 %\n",
      "83.349 %\n",
      "83.976 %\n",
      "84.602 %\n",
      "85.229 %\n",
      "85.856 %\n",
      "86.483 %\n",
      "87.109 %\n",
      "87.736 %\n",
      "88.363 %\n",
      "88.989 %\n",
      "89.616 %\n",
      "90.243 %\n",
      "90.869 %\n",
      "91.496 %\n",
      "92.123 %\n",
      "92.749 %\n",
      "93.376 %\n",
      "94.003 %\n",
      "94.629 %\n",
      "95.256 %\n",
      "95.883 %\n",
      "96.509 %\n",
      "97.136 %\n",
      "97.763 %\n",
      "98.389 %\n",
      "99.016 %\n",
      "99.643 %\n",
      "test_data\n",
      "0.001 %\n",
      "0.654 %\n",
      "1.306 %\n",
      "1.959 %\n",
      "2.612 %\n",
      "3.265 %\n",
      "3.918 %\n",
      "4.571 %\n",
      "5.224 %\n",
      "5.877 %\n",
      "6.53 %\n",
      "7.182 %\n",
      "7.835 %\n",
      "8.488 %\n",
      "9.141 %\n",
      "9.794 %\n",
      "10.447 %\n",
      "11.1 %\n",
      "11.753 %\n",
      "12.406 %\n",
      "13.059 %\n",
      "13.711 %\n",
      "14.364 %\n",
      "15.017 %\n",
      "15.67 %\n",
      "16.323 %\n",
      "16.976 %\n",
      "17.629 %\n",
      "18.282 %\n",
      "18.935 %\n",
      "19.588 %\n",
      "20.24 %\n",
      "20.893 %\n",
      "21.546 %\n",
      "22.199 %\n",
      "22.852 %\n",
      "23.505 %\n",
      "24.158 %\n",
      "24.811 %\n",
      "25.464 %\n",
      "26.116 %\n",
      "26.769 %\n",
      "27.422 %\n",
      "28.075 %\n",
      "28.728 %\n",
      "29.381 %\n",
      "30.034 %\n",
      "30.687 %\n",
      "31.34 %\n",
      "31.993 %\n",
      "32.645 %\n",
      "33.298 %\n",
      "33.951 %\n",
      "34.604 %\n",
      "35.257 %\n",
      "35.91 %\n",
      "36.563 %\n",
      "37.216 %\n",
      "37.869 %\n",
      "38.521 %\n",
      "39.174 %\n",
      "39.827 %\n",
      "40.48 %\n",
      "41.133 %\n",
      "41.786 %\n",
      "42.439 %\n",
      "43.092 %\n",
      "43.745 %\n",
      "44.398 %\n",
      "45.05 %\n",
      "45.703 %\n",
      "46.356 %\n",
      "47.009 %\n",
      "47.662 %\n",
      "48.315 %\n",
      "48.968 %\n",
      "49.621 %\n",
      "50.274 %\n",
      "50.926 %\n",
      "51.579 %\n",
      "52.232 %\n",
      "52.885 %\n",
      "53.538 %\n",
      "54.191 %\n",
      "54.844 %\n",
      "55.497 %\n",
      "56.15 %\n",
      "56.803 %\n",
      "57.455 %\n",
      "58.108 %\n",
      "58.761 %\n",
      "59.414 %\n",
      "60.067 %\n",
      "60.72 %\n",
      "61.373 %\n",
      "62.026 %\n",
      "62.679 %\n",
      "63.331 %\n",
      "63.984 %\n",
      "64.637 %\n",
      "65.29 %\n",
      "65.943 %\n",
      "66.596 %\n",
      "67.249 %\n",
      "67.902 %\n",
      "68.555 %\n",
      "69.208 %\n",
      "69.86 %\n",
      "70.513 %\n",
      "71.166 %\n",
      "71.819 %\n",
      "72.472 %\n",
      "73.125 %\n",
      "73.778 %\n",
      "74.431 %\n",
      "75.084 %\n",
      "75.736 %\n",
      "76.389 %\n",
      "77.042 %\n",
      "77.695 %\n",
      "78.348 %\n",
      "79.001 %\n",
      "79.654 %\n",
      "80.307 %\n",
      "80.96 %\n",
      "81.613 %\n",
      "82.265 %\n",
      "82.918 %\n",
      "83.571 %\n",
      "84.224 %\n",
      "84.877 %\n",
      "85.53 %\n",
      "86.183 %\n",
      "86.836 %\n",
      "87.489 %\n",
      "88.141 %\n",
      "88.794 %\n",
      "89.447 %\n",
      "90.1 %\n",
      "90.753 %\n",
      "91.406 %\n",
      "92.059 %\n",
      "92.712 %\n",
      "93.365 %\n",
      "94.018 %\n",
      "94.67 %\n",
      "95.323 %\n",
      "95.976 %\n",
      "96.629 %\n",
      "97.282 %\n",
      "97.935 %\n",
      "98.588 %\n",
      "99.241 %\n",
      "99.894 %\n"
     ]
    }
   ],
   "source": [
    "make_features(train_data,'train_data')\n",
    "make_features(test_data,'test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = io.mmread('train_data_X.mtx').tocsr()\n",
    "y_train = io.mmread('train_data_y.mtx').tocsr()\n",
    "X_test = io.mmread('test_data_X.mtx').tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nout = y_train.shape[1]\n",
    "nin = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=nin, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nout, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 568, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"<ipython-input-18-502eb4ddd061>\", line 3, in batch_generator\n",
      "    number_of_batches = samples_per_epoch/batch_size\n",
      "NameError: name 'samples_per_epoch' is not defined\n",
      "\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-502eb4ddd061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# to deal with sparse matrix, add generator: https://stackoverflow.com/questions/41538692/using-sparse-matrices-with-keras-and-tensorflow\n",
    "def batch_generator(X, y, batch_size):\n",
    "    number_of_batches = X.shape[0]/batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(np.shape(y)[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    X =  X[shuffle_index, :]\n",
    "    y =  y[shuffle_index]\n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[index_batch,:].todense()\n",
    "        y_batch = y[index_batch]\n",
    "        counter += 1\n",
    "        yield(np.array(X_batch),y_batch)\n",
    "        if (counter < number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0\n",
    "\n",
    "size_batch = 64\n",
    "nb_epoch=5\n",
    "            \n",
    "model.fit_generator(batch_generator(X_train[:1000,:], y_train[:1000,:], size_batch),X_train[:1000,:].shape[0], nb_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.save('model_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#score = model.evaluate_generator(batch_generator(X_test, y_test, nb_batch),len(range(0, X_test.shape[0], nb_batch)))\n",
    "#score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict_generator(batch_generator(X_test, y_test, nb_batch),len(range(0, X_test.shape[0], nb_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# put predictions into right format for saving\n",
    "columns = train_data.columns[:8]\n",
    "res = pd.DataFrame(columns=columns, index = test_data.index)\n",
    "res['id'] = test_data['id']\n",
    "res[res.columns[1:8]]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res.to_csv('NNwords.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
