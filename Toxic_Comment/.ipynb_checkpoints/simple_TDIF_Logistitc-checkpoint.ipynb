{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  neutral  \n",
      "0             0        0       0       0              0        1  \n",
      "1             0        0       0       0              0        1  \n",
      "2             0        0       0       0              0        1  \n",
      "3             0        0       0       0              0        1  \n",
      "4             0        0       0       0              0        1  \n"
     ]
    }
   ],
   "source": [
    "train_data['neutral'] = train_data.apply(lambda x: 0 if sum(x[2:8])>=1 else 1 ,axis = 1)\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  neutral  \\\n",
      "0             0        0       0       0              0        1   \n",
      "1             0        0       0       0              0        1   \n",
      "2             0        0       0       0              0        1   \n",
      "3             0        0       0       0              0        1   \n",
      "4             0        0       0       0              0        1   \n",
      "\n",
      "                                           processed  \n",
      "0  explanation why the edits made under my userna...  \n",
      "1  d aww  he matches this background colour i m s...  \n",
      "2  hey man  i m really not trying to edit war  it...  \n",
      "3    more i can t make any real suggestions on im...  \n",
      "4  you  sir  are my hero  any chance you remember...  \n",
      "                 id                                       comment_text  \\\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
      "\n",
      "                                           processed  \n",
      "0  yo bitch ja rule is more succesful then you ll...  \n",
      "1     from rfc       the title is fine as it is  ...  \n",
      "2          sources         zawe ashton on lapland...  \n",
      "3   if you have a look back at the source  the in...  \n",
      "4          i don t anonymously edit articles at all   \n"
     ]
    }
   ],
   "source": [
    "def process_comment_text(txt):\n",
    "    ntxt = re.sub(r\"[^a-zA-Z]\", \" \", txt)\n",
    "    ntxt = ntxt.lower()\n",
    "    return ntxt\n",
    "\n",
    "train_data['processed'] = train_data.comment_text.apply(process_comment_text)\n",
    "test_data['processed'] = test_data.comment_text.apply(process_comment_text)\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data.columns[2:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "<class 'str'>\n",
      "severe_toxic\n",
      "<class 'str'>\n",
      "obscene\n",
      "<class 'str'>\n",
      "threat\n",
      "<class 'str'>\n",
      "insult\n",
      "<class 'str'>\n",
      "identity_hate\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for c in train_data.columns[2:8]:\n",
    "    print(c)\n",
    "    print(type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=153164, step=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ad8fdf266f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;31m# array of numbers for the number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "def class_model(data,labels):\n",
    "    negative_ind = np.where(labels == 0)[0]\n",
    "    positive_ind = np.where (labels == 1)[0]\n",
    "    balance_negative = np.random.choice(negative_ind,size = len(positive_ind),replace = False)\n",
    "    train_ind = np.concatenate((positive_ind,balance_negative))\n",
    "    random.shuffle(train_ind)\n",
    "    print(len(train_ind))\n",
    "    data = data[train_ind,:]\n",
    "    print(data.shape)\n",
    "    labels = labels[train_ind]\n",
    "    print(len(labels))\n",
    "    model = LogisticRegression(C=100)\n",
    "    model.fit(data, labels)\n",
    "    return model\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(min_df=3,stop_words='english').fit(train_data.processed.values)\n",
    "x_train_vectorized = vect.transform(train_data.processed.values)\n",
    "x_test_vectorized = vect.transform(test_data.processed.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30588\n",
      "(30588, 50448)\n",
      "30588\n",
      "[0 1]\n",
      "[[  9.75397330e-09   9.99999990e-01]\n",
      " [  9.99988380e-01   1.16203712e-05]\n",
      " [  9.73617070e-01   2.63829302e-02]\n",
      " ..., \n",
      " [  9.86756135e-01   1.32438645e-02]\n",
      " [  7.36510605e-01   2.63489395e-01]\n",
      " [  2.47054704e-07   9.99999753e-01]]\n",
      "[  9.99999990e-01   1.16203712e-05   2.63829302e-02 ...,   1.32438645e-02\n",
      "   2.63489395e-01   9.99999753e-01]\n",
      "3190\n",
      "(3190, 50448)\n",
      "3190\n",
      "[0 1]\n",
      "[[ 0.00673595  0.99326405]\n",
      " [ 0.99071908  0.00928092]\n",
      " [ 0.97038937  0.02961063]\n",
      " ..., \n",
      " [ 0.9808596   0.0191404 ]\n",
      " [ 0.97767852  0.02232148]\n",
      " [ 0.95768652  0.04231348]]\n",
      "[ 0.99326405  0.00928092  0.02961063 ...,  0.0191404   0.02232148\n",
      "  0.04231348]\n",
      "16898\n",
      "(16898, 50448)\n",
      "16898\n",
      "[0 1]\n",
      "[[  1.01325160e-08   9.99999990e-01]\n",
      " [  9.99873627e-01   1.26372544e-04]\n",
      " [  9.39519707e-01   6.04802932e-02]\n",
      " ..., \n",
      " [  9.92030673e-01   7.96932680e-03]\n",
      " [  8.74340685e-01   1.25659315e-01]\n",
      " [  2.33477272e-04   9.99766523e-01]]\n",
      "[  9.99999990e-01   1.26372544e-04   6.04802932e-02 ...,   7.96932680e-03\n",
      "   1.25659315e-01   9.99766523e-01]\n",
      "956\n",
      "(956, 50448)\n",
      "956\n",
      "[0 1]\n",
      "[[ 0.04888357  0.95111643]\n",
      " [ 0.97276127  0.02723873]\n",
      " [ 0.95649341  0.04350659]\n",
      " ..., \n",
      " [ 0.97153861  0.02846139]\n",
      " [ 0.86131495  0.13868505]\n",
      " [ 0.77826233  0.22173767]]\n",
      "[ 0.95111643  0.02723873  0.04350659 ...,  0.02846139  0.13868505\n",
      "  0.22173767]\n",
      "15754\n",
      "(15754, 50448)\n",
      "15754\n",
      "[0 1]\n",
      "[[  7.04895616e-05   9.99929510e-01]\n",
      " [  9.96825061e-01   3.17493928e-03]\n",
      " [  9.65923341e-01   3.40766592e-02]\n",
      " ..., \n",
      " [  9.92417216e-01   7.58278359e-03]\n",
      " [  9.96649387e-01   3.35061251e-03]\n",
      " [  5.13633885e-04   9.99486366e-01]]\n",
      "[ 0.99992951  0.00317494  0.03407666 ...,  0.00758278  0.00335061\n",
      "  0.99948637]\n",
      "2810\n",
      "(2810, 50448)\n",
      "2810\n",
      "[0 1]\n",
      "[[ 0.00489492  0.99510508]\n",
      " [ 0.95021908  0.04978092]\n",
      " [ 0.92626624  0.07373376]\n",
      " ..., \n",
      " [ 0.98433355  0.01566645]\n",
      " [ 0.24262514  0.75737486]\n",
      " [ 0.53011825  0.46988175]]\n",
      "[ 0.99510508  0.04978092  0.07373376 ...,  0.01566645  0.75737486\n",
      "  0.46988175]\n"
     ]
    }
   ],
   "source": [
    "columns = ['id']\n",
    "index = test_data.index # array of numbers for the number of samples\n",
    "res = pd.DataFrame(columns=columns, index = index)\n",
    "\n",
    "\n",
    "for c in train_data.columns[2:8]:\n",
    "    labels = np.array(train_data[c])\n",
    "    mm = class_model(x_train_vectorized,labels)\n",
    "    print(mm.classes_)\n",
    "    predictions = mm.predict_proba(x_test_vectorized)\n",
    "    print(predictions)\n",
    "    print(predictions[:,np.squeeze(np.where(mm.classes_==1))])\n",
    "    res[c] = predictions[:,np.squeeze(np.where(mm.classes_==1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951116</td>\n",
       "      <td>9.999295e-01</td>\n",
       "      <td>0.995105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.027239</td>\n",
       "      <td>3.174939e-03</td>\n",
       "      <td>0.049781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.029611</td>\n",
       "      <td>0.060480</td>\n",
       "      <td>0.043507</td>\n",
       "      <td>3.407666e-02</td>\n",
       "      <td>0.073734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.042902</td>\n",
       "      <td>1.011984e-03</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018765</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.100480</td>\n",
       "      <td>2.141854e-02</td>\n",
       "      <td>0.047377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103391</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>2.048912e-04</td>\n",
       "      <td>0.007557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>5.861770e-03</td>\n",
       "      <td>0.003697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.047096</td>\n",
       "      <td>0.133125</td>\n",
       "      <td>0.297377</td>\n",
       "      <td>9.064032e-01</td>\n",
       "      <td>0.087985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.074943</td>\n",
       "      <td>7.180873e-02</td>\n",
       "      <td>0.090394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.050422</td>\n",
       "      <td>1.306320e-03</td>\n",
       "      <td>0.023280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.921820</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>6.799619e-01</td>\n",
       "      <td>0.010137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158717</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.072205</td>\n",
       "      <td>0.021634</td>\n",
       "      <td>1.381368e-02</td>\n",
       "      <td>0.103693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>3.670834e-02</td>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.024557</td>\n",
       "      <td>0.051596</td>\n",
       "      <td>1.305721e-02</td>\n",
       "      <td>0.032887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>4.196897e-04</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.393285</td>\n",
       "      <td>0.012966</td>\n",
       "      <td>0.023833</td>\n",
       "      <td>0.068902</td>\n",
       "      <td>2.468028e-02</td>\n",
       "      <td>0.072533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122979</td>\n",
       "      <td>0.103679</td>\n",
       "      <td>0.066786</td>\n",
       "      <td>0.119504</td>\n",
       "      <td>9.378196e-02</td>\n",
       "      <td>0.191297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081124</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>1.188834e-02</td>\n",
       "      <td>0.010297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>5.331458e-04</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>6.564932e-03</td>\n",
       "      <td>0.002875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.057131</td>\n",
       "      <td>0.017611</td>\n",
       "      <td>0.051924</td>\n",
       "      <td>6.378745e-03</td>\n",
       "      <td>0.052036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.462583</td>\n",
       "      <td>0.255729</td>\n",
       "      <td>0.082571</td>\n",
       "      <td>0.512481</td>\n",
       "      <td>3.225639e-01</td>\n",
       "      <td>0.892834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742261</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.026352</td>\n",
       "      <td>0.026024</td>\n",
       "      <td>5.502179e-02</td>\n",
       "      <td>0.198675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.065760</td>\n",
       "      <td>4.729763e-03</td>\n",
       "      <td>0.097806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767871</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.646698</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>5.230546e-03</td>\n",
       "      <td>0.201452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.081645</td>\n",
       "      <td>4.040881e-02</td>\n",
       "      <td>0.074165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.142349</td>\n",
       "      <td>7.126401e-02</td>\n",
       "      <td>0.130156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077180</td>\n",
       "      <td>0.086798</td>\n",
       "      <td>0.087565</td>\n",
       "      <td>0.050128</td>\n",
       "      <td>4.179311e-02</td>\n",
       "      <td>0.221932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825224</td>\n",
       "      <td>0.629533</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.263336</td>\n",
       "      <td>1.049643e-01</td>\n",
       "      <td>0.996393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060092</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>0.043035</td>\n",
       "      <td>2.440734e-02</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153134</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.379502</td>\n",
       "      <td>0.051774</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.053317</td>\n",
       "      <td>4.758503e-03</td>\n",
       "      <td>0.048418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153135</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>5.446497e-03</td>\n",
       "      <td>0.108297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153136</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.026985</td>\n",
       "      <td>2.351178e-02</td>\n",
       "      <td>0.007067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153137</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150566</td>\n",
       "      <td>0.107637</td>\n",
       "      <td>0.030510</td>\n",
       "      <td>0.290996</td>\n",
       "      <td>3.571184e-01</td>\n",
       "      <td>0.323875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153138</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.052312</td>\n",
       "      <td>9.591239e-02</td>\n",
       "      <td>0.144857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153139</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.009321</td>\n",
       "      <td>0.026479</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>2.958660e-02</td>\n",
       "      <td>0.038360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153140</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.011088</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.034674</td>\n",
       "      <td>2.010002e-02</td>\n",
       "      <td>0.069902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153141</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016103</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>2.347405e-03</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153142</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060656</td>\n",
       "      <td>0.114793</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.124650</td>\n",
       "      <td>4.051735e-01</td>\n",
       "      <td>0.252618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153143</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.877202</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.105732</td>\n",
       "      <td>9.220884e-01</td>\n",
       "      <td>0.806112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.022460</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.022956</td>\n",
       "      <td>8.912092e-07</td>\n",
       "      <td>0.011680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.019304</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.038146</td>\n",
       "      <td>4.572869e-03</td>\n",
       "      <td>0.115702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.027062</td>\n",
       "      <td>1.935270e-04</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039109</td>\n",
       "      <td>0.060607</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.026458</td>\n",
       "      <td>9.442599e-02</td>\n",
       "      <td>0.025135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874768</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.099080</td>\n",
       "      <td>2.022869e-03</td>\n",
       "      <td>0.074895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998074</td>\n",
       "      <td>0.710369</td>\n",
       "      <td>0.147235</td>\n",
       "      <td>0.543651</td>\n",
       "      <td>9.286121e-01</td>\n",
       "      <td>0.613471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>5.093193e-04</td>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772082</td>\n",
       "      <td>0.315926</td>\n",
       "      <td>0.402459</td>\n",
       "      <td>0.052826</td>\n",
       "      <td>7.514878e-01</td>\n",
       "      <td>0.344503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722340</td>\n",
       "      <td>0.343936</td>\n",
       "      <td>0.962487</td>\n",
       "      <td>0.259851</td>\n",
       "      <td>3.452246e-02</td>\n",
       "      <td>0.476925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998491</td>\n",
       "      <td>0.085387</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.918709</td>\n",
       "      <td>3.429973e-01</td>\n",
       "      <td>0.486705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>0.033030</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.163243</td>\n",
       "      <td>5.618160e-01</td>\n",
       "      <td>0.939966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.965297</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.097393</td>\n",
       "      <td>9.999900e-01</td>\n",
       "      <td>0.993764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208999</td>\n",
       "      <td>0.079436</td>\n",
       "      <td>0.046755</td>\n",
       "      <td>0.087772</td>\n",
       "      <td>9.492540e-02</td>\n",
       "      <td>0.134776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040346</td>\n",
       "      <td>0.009691</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>2.726533e-03</td>\n",
       "      <td>0.018762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.749080</td>\n",
       "      <td>0.547481</td>\n",
       "      <td>0.020922</td>\n",
       "      <td>9.968549e-01</td>\n",
       "      <td>0.146197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.934470</td>\n",
       "      <td>0.042988</td>\n",
       "      <td>9.299291e-01</td>\n",
       "      <td>0.279732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190448</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.138273</td>\n",
       "      <td>0.389848</td>\n",
       "      <td>2.089131e-01</td>\n",
       "      <td>0.067397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.019140</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>7.582784e-03</td>\n",
       "      <td>0.015666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.125659</td>\n",
       "      <td>0.138685</td>\n",
       "      <td>3.350613e-03</td>\n",
       "      <td>0.757375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042313</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.221738</td>\n",
       "      <td>9.994864e-01</td>\n",
       "      <td>0.469882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     toxic  severe_toxic   obscene    threat        insult  \\\n",
       "0       NaN  1.000000      0.993264  1.000000  0.951116  9.999295e-01   \n",
       "1       NaN  0.000012      0.009281  0.000126  0.027239  3.174939e-03   \n",
       "2       NaN  0.026383      0.029611  0.060480  0.043507  3.407666e-02   \n",
       "3       NaN  0.000329      0.002824  0.001246  0.042902  1.011984e-03   \n",
       "4       NaN  0.018765      0.049887  0.015589  0.100480  2.141854e-02   \n",
       "5       NaN  0.103391      0.006401  0.007901  0.017226  2.048912e-04   \n",
       "6       NaN  0.000724      0.002700  0.003443  0.009621  5.861770e-03   \n",
       "7       NaN  0.999860      0.047096  0.133125  0.297377  9.064032e-01   \n",
       "8       NaN  0.041290      0.010109  0.011706  0.074943  7.180873e-02   \n",
       "9       NaN  0.000051      0.002252  0.003874  0.050422  1.306320e-03   \n",
       "10      NaN  0.996120      0.012343  0.921820  0.008726  6.799619e-01   \n",
       "11      NaN  0.158717      0.014493  0.072205  0.021634  1.381368e-02   \n",
       "12      NaN  0.001140      0.001873  0.000126  0.020908  3.670834e-02   \n",
       "13      NaN  0.000033      0.021773  0.024557  0.051596  1.305721e-02   \n",
       "14      NaN  0.000542      0.000400  0.001365  0.004961  4.196897e-04   \n",
       "15      NaN  0.393285      0.012966  0.023833  0.068902  2.468028e-02   \n",
       "16      NaN  0.122979      0.103679  0.066786  0.119504  9.378196e-02   \n",
       "17      NaN  0.081124      0.001058  0.012270  0.024073  1.188834e-02   \n",
       "18      NaN  0.000120      0.000014  0.000062  0.000436  5.331458e-04   \n",
       "19      NaN  0.009397      0.010497  0.003404  0.008509  6.564932e-03   \n",
       "20      NaN  0.000755      0.057131  0.017611  0.051924  6.378745e-03   \n",
       "21      NaN  0.462583      0.255729  0.082571  0.512481  3.225639e-01   \n",
       "22      NaN  0.742261      0.015833  0.026352  0.026024  5.502179e-02   \n",
       "23      NaN  0.000851      0.069110  0.001216  0.065760  4.729763e-03   \n",
       "24      NaN  0.767871      0.003853  0.646698  0.092217  5.230546e-03   \n",
       "25      NaN  0.002952      0.006289  0.003879  0.081645  4.040881e-02   \n",
       "26      NaN  0.008380      0.013258  0.032215  0.142349  7.126401e-02   \n",
       "27      NaN  0.077180      0.086798  0.087565  0.050128  4.179311e-02   \n",
       "28      NaN  0.825224      0.629533  0.005075  0.263336  1.049643e-01   \n",
       "29      NaN  0.060092      0.008401  0.010278  0.043035  2.440734e-02   \n",
       "...     ...       ...           ...       ...       ...           ...   \n",
       "153134  NaN  0.379502      0.051774  0.014799  0.053317  4.758503e-03   \n",
       "153135  NaN  0.004158      0.041176  0.008705  0.083200  5.446497e-03   \n",
       "153136  NaN  0.011799      0.016279  0.005784  0.026985  2.351178e-02   \n",
       "153137  NaN  0.150566      0.107637  0.030510  0.290996  3.571184e-01   \n",
       "153138  NaN  0.012612      0.020413  0.007490  0.052312  9.591239e-02   \n",
       "153139  NaN  0.017971      0.009321  0.026479  0.003247  2.958660e-02   \n",
       "153140  NaN  0.002543      0.011088  0.004559  0.034674  2.010002e-02   \n",
       "153141  NaN  0.016103      0.001898  0.001025  0.016449  2.347405e-03   \n",
       "153142  NaN  0.060656      0.114793  0.008066  0.124650  4.051735e-01   \n",
       "153143  NaN  0.999973      0.877202  0.999999  0.105732  9.220884e-01   \n",
       "153144  NaN  0.004498      0.022460  0.000856  0.022956  8.912092e-07   \n",
       "153145  NaN  0.006889      0.019304  0.004817  0.038146  4.572869e-03   \n",
       "153146  NaN  0.000111      0.002490  0.000144  0.027062  1.935270e-04   \n",
       "153147  NaN  0.039109      0.060607  0.003828  0.026458  9.442599e-02   \n",
       "153148  NaN  0.874768      0.012739  0.002104  0.099080  2.022869e-03   \n",
       "153149  NaN  0.998074      0.710369  0.147235  0.543651  9.286121e-01   \n",
       "153150  NaN  0.000679      0.000491  0.000977  0.019656  5.093193e-04   \n",
       "153151  NaN  0.772082      0.315926  0.402459  0.052826  7.514878e-01   \n",
       "153152  NaN  0.722340      0.343936  0.962487  0.259851  3.452246e-02   \n",
       "153153  NaN  0.998491      0.085387  0.999789  0.918709  3.429973e-01   \n",
       "153154  NaN  0.998886      0.033030  0.051019  0.163243  5.618160e-01   \n",
       "153155  NaN  0.999997      0.965297  0.999999  0.097393  9.999900e-01   \n",
       "153156  NaN  0.208999      0.079436  0.046755  0.087772  9.492540e-02   \n",
       "153157  NaN  0.040346      0.009691  0.007904  0.030940  2.726533e-03   \n",
       "153158  NaN  0.999878      0.749080  0.547481  0.020922  9.968549e-01   \n",
       "153159  NaN  0.989519      0.000044  0.934470  0.042988  9.299291e-01   \n",
       "153160  NaN  0.190448      0.078327  0.138273  0.389848  2.089131e-01   \n",
       "153161  NaN  0.013244      0.019140  0.007969  0.028461  7.582784e-03   \n",
       "153162  NaN  0.263489      0.022321  0.125659  0.138685  3.350613e-03   \n",
       "153163  NaN  1.000000      0.042313  0.999767  0.221738  9.994864e-01   \n",
       "\n",
       "        identity_hate  \n",
       "0            0.995105  \n",
       "1            0.049781  \n",
       "2            0.073734  \n",
       "3            0.002151  \n",
       "4            0.047377  \n",
       "5            0.007557  \n",
       "6            0.003697  \n",
       "7            0.087985  \n",
       "8            0.090394  \n",
       "9            0.023280  \n",
       "10           0.010137  \n",
       "11           0.103693  \n",
       "12           0.003074  \n",
       "13           0.032887  \n",
       "14           0.000146  \n",
       "15           0.072533  \n",
       "16           0.191297  \n",
       "17           0.010297  \n",
       "18           0.000051  \n",
       "19           0.002875  \n",
       "20           0.052036  \n",
       "21           0.892834  \n",
       "22           0.198675  \n",
       "23           0.097806  \n",
       "24           0.201452  \n",
       "25           0.074165  \n",
       "26           0.130156  \n",
       "27           0.221932  \n",
       "28           0.996393  \n",
       "29           0.008900  \n",
       "...               ...  \n",
       "153134       0.048418  \n",
       "153135       0.108297  \n",
       "153136       0.007067  \n",
       "153137       0.323875  \n",
       "153138       0.144857  \n",
       "153139       0.038360  \n",
       "153140       0.069902  \n",
       "153141       0.002001  \n",
       "153142       0.252618  \n",
       "153143       0.806112  \n",
       "153144       0.011680  \n",
       "153145       0.115702  \n",
       "153146       0.000713  \n",
       "153147       0.025135  \n",
       "153148       0.074895  \n",
       "153149       0.613471  \n",
       "153150       0.004060  \n",
       "153151       0.344503  \n",
       "153152       0.476925  \n",
       "153153       0.486705  \n",
       "153154       0.939966  \n",
       "153155       0.993764  \n",
       "153156       0.134776  \n",
       "153157       0.018762  \n",
       "153158       0.146197  \n",
       "153159       0.279732  \n",
       "153160       0.067397  \n",
       "153161       0.015666  \n",
       "153162       0.757375  \n",
       "153163       0.469882  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.where(mm.classes_==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30588\n",
      "(30588, 50448)\n",
      "30588\n",
      "[0 1]\n",
      "[[  2.01345118e-09   9.99999998e-01]\n",
      " [  9.97151498e-01   2.84850209e-03]\n",
      " [  9.74021387e-01   2.59786127e-02]\n",
      " ..., \n",
      " [  9.81391800e-01   1.86081998e-02]\n",
      " [  8.45975913e-01   1.54024087e-01]\n",
      " [  2.66272000e-08   9.99999973e-01]]\n",
      "[ 1.          0.0028485   0.02597861 ...,  0.0186082   0.15402409\n",
      "  0.99999997]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(train_data.toxic)\n",
    "mm = class_model(x_train_vectorized,labels)\n",
    "print(mm.classes_)\n",
    "predictions = mm.predict_proba(x_test_vectorized)\n",
    "print(predictions)\n",
    "print(predictions[:,np.squeeze(np.where(mm.classes_==1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(x_train,x_test):\n",
    "    vect = TfidfVectorizer(min_df=3,stop_words='english').fit(x_train)\n",
    "    x_train_vectorized = vect.transform(x_train)\n",
    "    x_test_vectorized = vect.transform(x_test)\n",
    "    return x_train_vectorized,x_test_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_data(data,labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15294\n",
      "144277\n"
     ]
    }
   ],
   "source": [
    "data = train_data.processed.values\n",
    "labels = np.array(train_data.toxic)\n",
    "print(len(labels[labels == 1]))\n",
    "print(len(labels[labels== 0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[labels == 1])+len(labels[labels== 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15294\n",
      "15294\n"
     ]
    }
   ],
   "source": [
    "negative_ind = np.where(labels == 0)[0]\n",
    "positive_ind = np.where (labels == 1)[0]\n",
    "balance_negative = np.random.choice(negative_ind,size = len(positive_ind),replace = False)\n",
    "print(len(balance_negative))\n",
    "print(len(positive_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30588\n"
     ]
    }
   ],
   "source": [
    "train_ind = np.concatenate((positive_ind,balance_negative))\n",
    "random.shuffle(train_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-84127fdc26c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "data = data[train_ind]\n",
    "labels = labels[train_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30588,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15294\n",
      "15294\n"
     ]
    }
   ],
   "source": [
    "print(len(labels[labels == 1]))\n",
    "print(len(labels[labels== 0] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Vs All approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 17835 features per sample; expecting 15748",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-05aa2ed49437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx_test_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Your answer here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sapaz3/anaconda/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sapaz3/anaconda/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 305\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 17835 features per sample; expecting 15748"
     ]
    }
   ],
   "source": [
    "def class_model(data,labels):\n",
    "    vectoriser = TfidfVectorizer(min_df=3,stop_words='english').fit(data)\n",
    "    x_train_vectorized = vectoriser.transform(data)\n",
    "    \n",
    "    negative_ind = np.where(labels == 0)[0]\n",
    "    positive_ind = np.where (labels == 1)[0]\n",
    "    balance_negative = np.random.choice(negative_ind,size = len(positive_ind),replace = False)\n",
    "    train_ind = np.concatenate((positive_ind,balance_negative))\n",
    "    random.shuffle(train_ind)\n",
    "    data = data[train_ind]\n",
    "    labels = labels[train_ind]\n",
    "    model = LogisticRegression(C=100)\n",
    "    model.fit(x_train_vec, y_train)\n",
    "    return vectoriser, model\n",
    "\n",
    "mv,mm = class_model(data,labels)\n",
    "x_test_vec = mv.transform(test_data.processed.values)\n",
    "predictions = mm.predict(x_test_vec)\n",
    "roc_auc_score(y_test, predictions)#Your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labels = np.array(train_data.neutral)\n",
    "x_train,x_test,y_train,y_test = train_test_split(data,labels,test_size = 0.2,stratify=labels,random_state = 42)\n",
    "x_train_vec,x_test_vec = vectorize(x_train,x_test)\n",
    "#x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.2,random_state = 42)\n",
    "#x_train_vec,x_val_vec = vectorize(x_train,x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC(C=0.1)\n",
    "model.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_chars_test = x_test.str.len()\n",
    "predictions = model.predict(x_test_vec)\n",
    "roc_auc_score(y_test, predictions)#Your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888852566198\n",
      "[[2772  287]\n",
      " [ 393 2666]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88885256619810393"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=100)\n",
    "model.fit(x_train_vec, y_train)\n",
    "predictions = model.predict(x_test_vec)\n",
    "print(roc_auc_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict_proba(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(x_train_vec, y_train)\n",
    "predictions = clf.predict(x_test_vec)\n",
    "print(roc_auc_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(y_train[y_train==0])/len(y_train[y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "#scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['linear'], 'C': [1, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5, scoring='accuracy')\n",
    "clf.fit(x_train_vec, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "for params, mean_score, scores in clf.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(x_test_vec)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
